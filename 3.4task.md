<h4>Задание 1.</h4>
```bash
vagrant@vagrant:~$ cat /etc/systemd/system/node_exporter.service
[Unit]
Description=Node exporter

[Service]
EnvironmentFile=-/etc/node-exporter/ne.conf
ExecStart=/opt/node_exporter-1.2.2.linux-amd64/node_exporter 

[Install]
WantedBy=multi-user.target
```
После перезапуска: 
```bash
vagrant@vagrant:~$ uptime
 18:31:46 up 0 min,  1 user,  load average: 1.04, 0.23, 0.08
vagrant@vagrant:~$ curl http://localhost:9100/metrics
# HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.
# TYPE go_gc_duration_seconds summary
go_gc_duration_seconds{quantile="0"} 0
go_gc_duration_seconds{quantile="0.25"} 0
go_gc_duration_seconds{quantile="0.5"} 0
go_gc_duration_seconds{quantile="0.75"} 0
go_gc_duration_seconds{quantile="1"} 0
go_gc_duration_seconds_sum 0
```
Остановка и запуск 
```bash
root@vagrant:/home/vagrant# systemctl stop node_exporter
root@vagrant:/home/vagrant# ps -ux | grep node
root         952  0.0  0.0   8900   736 pts/0    S+   18:43   0:00 grep --color=auto node
root@vagrant:/home/vagrant# systemctl start node_exporter
root@vagrant:/home/vagrant# ps -ux | grep node
root         955  0.0  1.1 714768 11292 ?        Ssl  18:43   0:00 /opt/node_exporter-1.2.2.linux-amd64/node_exporter
root         970  0.0  0.0   8900   672 pts/0    S+   18:43   0:00 grep --color=auto node
```
<hr>
<h4>Задание 2.</h4>

CPU
```bash
node_cpu_seconds_total{cpu="0",mode="idle"} 417.33
node_cpu_seconds_total{cpu="0",mode="iowait"} 1.18
node_cpu_seconds_total{cpu="0",mode="system"} 2.92
node_cpu_seconds_total{cpu="0",mode="user"} 2.54
```
RAM
```bash
node_memory_MemAvailable_bytes 7.66681088e+08
node_memory_MemFree_bytes 6.33786368e+08
```
HDD
```bash
node_disk_io_time_seconds_total{device="dm-0"} 4.604
node_disk_read_bytes_total{device="dm-0"} 2.50053632e+08
node_disk_read_time_seconds_total{device="dm-0"} 10.056000000000001
node_disk_written_bytes_total{device="dm-0"} 1.421312e+07
node_disk_write_time_seconds_total{device="dm-0"} 0.8240000000000001
```
network
```bash
node_network_receive_bytes_total{device="eth0"} 42806
node_network_receive_errs_total{device="eth0"} 0
node_network_transmit_bytes_total{device="eth0"} 98363
node_network_transmit_errs_total{device="eth0"} 0
```
<hr>
<h4>Задание 3.</h4>

Сделано https://i.imgur.com/9gt87WA.png
<hr>
<h4>Задание 4.</h4>

Да, сначала нашла 
[    0.155079] Booting paravirtualized kernel on KVM

Потом грепом 
```bash
vagrant@vagrant:~$ dmesg | grep virtual
[    0.008306] CPU MTRRs all blank - virtualized system.
[    0.155079] Booting paravirtualized kernel on KVM
[    2.929472] systemd[1]: Detected virtualization oracle.
```
<hr>
<h4>Задание 5.</h4>
Задает макс возможное число файловых дескрипторов в системе

По умолчанию

```bash
vagrant@vagrant:~$ sysctl -n fs.nr_open
1048576
```
Есть еще fs.file-max - максимальное кол-во открытых файлов

Лимиты на пользователя:
```bash
vagrant@vagrant:~$ ulimit -Sn
1024
vagrant@vagrant:~$ ulimit -Hn
1048576
```
<hr>
<h4>Задание 6.</h4>

```bash
root@vagrant:/home/vagrant# ps -ux | grep sleep
root        1248  0.0  0.0   8080   592 pts/1    S+   20:05   0:00 unshare -f --pid --mount-proc sleep 1h
root        1249  0.0  0.0   8076   592 pts/1    S+   20:05   0:00 sleep 1h
root        1253  0.0  0.0   8900   736 pts/0    S+   20:05   0:00 grep --color=auto sleep
root@vagrant:/home/vagrant# nsenter --target 1249 --pid --mount
root@vagrant:/# ps -aux
USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root           1  0.0  0.0   8076   592 pts/1    S+   20:05   0:00 sleep 1h
root           2  0.0  0.3   9836  3912 pts/0    S    20:05   0:00 -bash
root          11  0.0  0.3  11680  3584 pts/0    R+   20:06   0:00 ps -aux

```
<hr>
<h4>Задание 7.</h4>

:(){ :|:& };: - fork bomb
Бесконечно плодит процессы
```bash
[  359.873826] cgroup: fork rejected by pids controller in /user.slice/user-1000.slice/session-4.scope
[  363.048284] cgroup: fork rejected by pids controller in /user.slice/user-1000.slice/session-3.scope
```

Сработало ограничение на число процессов 
root@vagrant:/home/vagrant# cat /sys/fs/cgroup/pids/user.slice/user-1000.slice/pids.max
2356

Ограничить кол-во запускаемых пользователем процессов можно через ulimit -u
